# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

TheilUfunction <- function(y, yPred) {
    .Call('mlRFinance_TheilUfunction', PACKAGE = 'mlRFinance', y, yPred)
}

ErrorMeasures <- function(y, yPred) {
    .Call('mlRFinance_ErrorMeasures', PACKAGE = 'mlRFinance', y, yPred)
}

ErrorMeasuresBinary <- function(y, yPred) {
    .Call('mlRFinance_ErrorMeasuresBinary', PACKAGE = 'mlRFinance', y, yPred)
}

#' @name QPFS
#' @title QPFS - Quadratic Programming Feature Selection.
#' @description Feature Selection:
#'
#' @param Q Similarity Matrix. Dimension equal PxP.
#' @param f Relevance vector. Dimension equal Px1
#' @param alpha Weight between Similarity and Relevance (Keep NA to automatic choose alpha)
#' @return Weights for each variable presented in matrix X
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

QPFS <- function(Q, f, alpha) {
    .Call('mlRFinance_QPFS', PACKAGE = 'mlRFinance', Q, f, alpha)
}

#' @name Garch C-SVR L1
#' @title Garch C-SVR L1 - Garch Support Vector Regression with C cost and L1 regularization.
#' @description Training and Forecasting volatility
#'
#' @param train Vector of returns (training set). Dimension equal Nx1.
#' @param valid Vector of returns (validation set). Dimension equal Mx1.
#' @param C Cost parameter. Should be C>0.
#' @param epsilon Insentitive band. Should be epsilon>0.
#' @param kernel Name of the kernel that will be used for the mean equation.
#' @param parms Parameters associated with chosen kenel for the mean equation.
#' @param kernel Name of the kernel that will be used for the mean equation.
#' @param parms Parameters associated with chosen kenel for the mean equation.
#' @return List Support Vectors Mean, Forecast mean, EAMmean,
#' Support Vectors Volatility, Forecast volatility, EAMvolat, .
#' If the results for the Support Vectors are NaN it means that
#' there is no Support Vector and the Quadratic Programming Problem
#' is unfeasible.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

GARCHCSVRL1 <- function(train, valid, Cmean, epsilonMean, Cvola, epsilonVola, kernelMean, parmsMean, kernelVolat, parmsVola) {
    .Call('mlRFinance_GARCHCSVRL1', PACKAGE = 'mlRFinance', train, valid, Cmean, epsilonMean, Cvola, epsilonVola, kernelMean, parmsMean, kernelVolat, parmsVola)
}

KernelMatrixComputation <- function(datMat, stringValue, parms) {
    .Call('mlRFinance_KernelMatrixComputation', PACKAGE = 'mlRFinance', datMat, stringValue, parms)
}

KernelMatrixComputationPred <- function(datMat, predMat, stringValue, parms) {
    .Call('mlRFinance_KernelMatrixComputationPred', PACKAGE = 'mlRFinance', datMat, predMat, stringValue, parms)
}

KernelMatrixComputationValue <- function(datMat, predMat, stringValue, parms) {
    .Call('mlRFinance_KernelMatrixComputationValue', PACKAGE = 'mlRFinance', datMat, predMat, stringValue, parms)
}

#' @name KPCA
#' @title Kernel PCA
#' @description Compute Kernel PCA
#'
#'
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return List with Principal Componentes, Variability, Eigenvectors and EigenValues
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

KPCAMatrix <- function(X, kernel, parms) {
    .Call('mlRFinance_KPCAMatrix', PACKAGE = 'mlRFinance', X, kernel, parms)
}

parallelMatrixSqrt <- function(x) {
    .Call('mlRFinance_parallelMatrixSqrt', PACKAGE = 'mlRFinance', x)
}

rcpp_parallel_js_distance <- function(mat) {
    .Call('mlRFinance_rcpp_parallel_js_distance', PACKAGE = 'mlRFinance', mat)
}

#' @name Portfolio Selection C-SVR L1
#' @title Portfolio Selection C-SVR L1 - Portfolio Selection Support Vector Regression
#' with C cost and L1 regularization.
#' @description Training and Forecasting the portfolio
#'
#' @param y_train Binary Vector of good (+1) and bad (-1) firms. Dimension equal Nx1.
#' @param X_train Fundamental matrix explaining the y_train, y_train_t=f(X_train_(t-1)). Dimension equal NxP.
#' @param y_valid Binary Vector of good (+1) and bad (-1) firms. Dimension equal Mx1.
#' @param X_valid Fundamental matrix explaining the y_train, y_train_t=f(X_train_(t-1)). Dimension equal MxP.
#' @param C Cost parameter. Should be C>0.
#' @param kernel Name of the kernel that will be used for the mean equation.
#' @param parms Parameters associated with chosen kenel for the mean equation.
#' @param typePredict 0-Binary(-1,+1), 1-Probability, 2- Raw result
#' @return List Support Vectors, Forecast , EAM
#' If the results for the Support Vectors are NaN it means that
#' there is no Support Vector and the Quadratic Programming Problem
#' is unfeasible.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

PortfolioSelectionCSVML1 <- function(y_train, X_train, y_valid, X_valid, C, kernel, parms, typePredict) {
    .Call('mlRFinance_PortfolioSelectionCSVML1', PACKAGE = 'mlRFinance', y_train, X_train, y_valid, X_valid, C, kernel, parms, typePredict)
}

PortfolioSelectionCSVRL1 <- function(y_train, X_train, y_valid, X_valid, C, epsilon, kernel, parms) {
    .Call('mlRFinance_PortfolioSelectionCSVRL1', PACKAGE = 'mlRFinance', y_train, X_train, y_valid, X_valid, C, epsilon, kernel, parms)
}

PortfolioSelectionSVWQR1 <- function(y_train, X_train, C, tau, gamma, kernel, parms) {
    .Call('mlRFinance_PortfolioSelectionSVWQR1', PACKAGE = 'mlRFinance', y_train, X_train, C, tau, gamma, kernel, parms)
}

rcppeigen_quadratic_solve <- function(G, g0, CE, ce0, CI, ci0) {
    .Call('mlRFinance_rcppeigen_quadratic_solve', PACKAGE = 'mlRFinance', G, g0, CE, ce0, CI, ci0)
}

FWERkControl <- function(test_stat, boot_stat, k, alpha) {
    .Call('mlRFinance_FWERkControl', PACKAGE = 'mlRFinance', test_stat, boot_stat, k, alpha)
}

FDPControl <- function(test_stat, boot_stat, gamma, alpha) {
    .Call('mlRFinance_FDPControl', PACKAGE = 'mlRFinance', test_stat, boot_stat, gamma, alpha)
}

#' @name WOC-SCM
#' @title WOC-SCM - Support Vector Clustering
#' @description Optimize the Lagrange multiplier for the WOC-SCM:
#'
#' Min (1/2)u^{t}Qu+g^{t}u
#' s.t.
#' 0<=u<=wi*C
#' sum ui=1
#' where g=diag(K) and Q=-2K
#' C is the Cost parameter, wi weights for each observation
#'
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param C Cost parameter. Should be C>=0.
#' @param k Total number of clusters.
#' @param sigma Similarity parameter.
#' @param inter Total number of interations.
#' @param parms Parameters associated with chosen kenel.
#' @return List Support Vectors, Kernel used, parameters and similarity matrix.
#' If the results for the Support Vectors are NaN it means that
#' there is no Support Vector and the Quadratic Programming Problem
#' is unfeasible.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#'             5,5,2,1,
#'             8,1,1,7),nrow=4,ncol=3)
#' svc<-WOCSCM(A, 1, 2, 1, 100, "Gaussian", c(0.5))
#' svc
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @name WOC-SCM
#' @title WOC-SCM - Support Vector Clustering
#' @description Optimize the Lagrange multiplier for the WOC-SCM:
#'
#' Min (1/2)u^{t}Qu+g^{t}u
#' s.t.
#' 0<=u<=wi*C
#' sum ui=1
#' where g=diag(K) and Q=-2K
#' C is the Cost parameter, wi weights for each observation
#'
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param wMat Weight Numeric matrix. Dimension equal NxN
#' @param C Cost parameter. Should be C>=0.
#' @param k Total number of clusters.
#' @param sigma Similarity parameter (between 0 and 1).
#' @param inter Total number of interations.
#' @param parms Parameters associated with chosen kenel.
#' @return List Support Vectors, Kernel used, parameters and similarity matrix.
#' If the results for the Support Vectors are NaN it means that
#' there is no Support Vector and the Quadratic Programming Problem
#' is unfeasible.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#'             5,5,2,1,
#'             8,1,1,7),nrow=4,ncol=3)
#' svc<-WOCSCM(A, 1, 2, 1, 100, "Gaussian", c(0.5))
#' svc
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

WOCSCM <- function(X, C, k, sigma, inter, kernel, parms) {
    .Call('mlRFinance_WOCSCM', PACKAGE = 'mlRFinance', X, C, k, sigma, inter, kernel, parms)
}

CSVC <- function(X, C, kernel, parms) {
    .Call('mlRFinance_CSVC', PACKAGE = 'mlRFinance', X, C, kernel, parms)
}

SpatialWOCSCM <- function(X, wMat, C, k, gamma1, gamma2, inter, kernel, parms) {
    .Call('mlRFinance_SpatialWOCSCM', PACKAGE = 'mlRFinance', X, wMat, C, k, gamma1, gamma2, inter, kernel, parms)
}

#' @name CSVML1
#' @title C-SVM L1 - Support Vector Regression with C cost and L1 regularization.
#' @description Optimize the Lagrange multiplier for the C-SVM L1:
#'
#' Min (1/2)u^{t}Qu-1^{t}u
#' s.t.
#' 0<=u<=C1
#'
#' where d is the vector of dependent variable,
#' and Q=K.*(d*t(d))=DKD. C is the Cost parameter.
#'
#' @param y Vector with dependent variables should be -1 or +1. Dimension equal Nx1.
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param C Cost parameter. Should be C>0.
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return List Support Vectors, Kernel used and parameters.
#' If the results for the Support Vectors are NaN it means that
#' there is no Support Vector and the Quadratic Programming Problem
#' is unfeasible.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @name Predicted CSVML1
#' @title C-SVM L1 - Support Vector Regression with C cost and L1 regularization.
#' @description Prediction for the C-SVR L1:
#'
#' f(x)=Sum_{i=1}^{N}(lambda*-lambda)K(x_{i},x)
#' @param CSVML1 List of Results of the CSVML1
#' @param y Numeric vector with the response variable. Dimension equal Nx1
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param Xprev Numeric matrix with the explanatory variables (predicted). Dimension equal MxP
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @param typePredict 0-Binary(-1,+1), 1-Probability, 2- Raw result
#' @return Eigen::VectorXd with the predicted values for Xpred
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @name Pseudo R2 - Predicted CSVRL1
#' @title C-SVR L1 - Support Vector Regression with C cost and L1 regularization.
#' @description Prediction for the C-SVR L1:
#'
#' f(x)=Sum_{i=1}^{N}(lambda*-lambda)K(x_{i},x)
#' @param CSVRL1 List of Results of the CSVRL1
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return Eigen::VectorXd with the Pseudo R2 for each variable.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @name CSVML2
#' @title C-SVM L2 - Support Vector Regression with C cost and L2 regularization.
#' @description Optimize the Lagrange multiplier for the C-SVM L2:
#'
#' Min (1/2)u^{t}Qu-1^{t}u
#' s.t.
#' u>=0
#'
#' where d is the vector of dependent variable,
#' and Q=(K+I/C).*(t(d)*d). C is the Cost parameter.
#'
#' @param y Vector with dependent variables should be -1 or +1. Dimension equal Nx1.
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param C Cost parameter. Should be C>0.
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return List Support Vectors, Kernel used and parameters.
#' If the results for the Support Vectors are NaN it means that
#' there is no Support Vector and the Quadratic Programming Problem
#' is unfeasible.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML2(d, A, 1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @name nuSVM
#' @title nu-SVM - Support Vector Regression with nu parameter.
#' @description The m-support vector classification (Scholkopf, Smola,
#' Williamson, & Bartlett, 2000) uses a new parameter nu which controls
#' the number of support vectors and training errors. The
#' parameter nu in (0, 1] is an upper bound on the fraction of training
#' errors and a lower bound of the fraction of support vectors.
#'
#' Min (1/2)u^{t}Qu-1^{t}u
#' s.t.
#' d^{t}*u=0
#' nu <=1^t*u
#' 0<=u<=1/l
#'
#' where d is the vector of dependent variable,
#' and Q=K.*(t(d)*d). nu is the parameter.
#'
#' @param y Vector with dependent variables should be -1 or +1. Dimension equal Nx1.
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param C Cost parameter. Should be C>0.
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return List Support Vectors, Kernel used and parameters.
#' If the results for the Support Vectors are NaN it means that
#' there is no Support Vector and the Quadratic Programming Problem
#' is unfeasible.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- nuSVM(d, A, 0.2, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

CSVML1 <- function(y, X, C, kernel, parms, biasTerm) {
    .Call('mlRFinance_CSVML1', PACKAGE = 'mlRFinance', y, X, C, kernel, parms, biasTerm)
}

PredictedCSVML1 <- function(CSVML1, y, X, Xprev, typePredict, biasTerm) {
    .Call('mlRFinance_PredictedCSVML1', PACKAGE = 'mlRFinance', CSVML1, y, X, Xprev, typePredict, biasTerm)
}

R2PredictedCSVML1 <- function(CSVML1, y, X, typePredict, biasTerm) {
    .Call('mlRFinance_R2PredictedCSVML1', PACKAGE = 'mlRFinance', CSVML1, y, X, typePredict, biasTerm)
}

CSVML2 <- function(y, X, C, kernel, parms, biasTerm) {
    .Call('mlRFinance_CSVML2', PACKAGE = 'mlRFinance', y, X, C, kernel, parms, biasTerm)
}

nuSVM <- function(y, X, nu, kernel, parms) {
    .Call('mlRFinance_nuSVM', PACKAGE = 'mlRFinance', y, X, nu, kernel, parms)
}

solveTest <- function(Dmat, dvec, Amat, bvec, CE, ce) {
    .Call('mlRFinance_solveTest', PACKAGE = 'mlRFinance', Dmat, dvec, Amat, bvec, CE, ce)
}

solveTest2 <- function(Dmat, dvec, Amat, bvec) {
    .Call('mlRFinance_solveTest2', PACKAGE = 'mlRFinance', Dmat, dvec, Amat, bvec)
}

CSVMplusL1 <- function(y, X, Z, C, gamma, kappa, kernel, parms, kernelStar, parmsStar, biasTerm) {
    .Call('mlRFinance_CSVMplusL1', PACKAGE = 'mlRFinance', y, X, Z, C, gamma, kappa, kernel, parms, kernelStar, parmsStar, biasTerm)
}

#' @name CSVRL1
#' @title C-SVR L1 - Support Vector Regression with C cost and L1 regularization.
#' @description Optimize the Lagrange multiplier for the C-SVR L1:
#'
#' Min (1/2)u^{t}Qu+g^{t}u
#' s.t.
#' 0<=u<=C1
#'
#' where u=(lambda*,lambda), g=(e-y,e+y)
#' and Q=|K -K|.
#'       |-K K|
#' C is the Cost parameter and e (epsilon) is the insentitive band
#'
#' @param y Vector with dependent variables. Dimension equal Nx1.
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param C Cost parameter. Should be C>0.
#' @param epsilon Insentitive band. Should be epsilon>0.
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return List Support Vectors, Kernel used and parameters.
#' If the results for the Support Vectors are NaN it means that
#' there is no Support Vector and the Quadratic Programming Problem
#' is unfeasible.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @name Predicted CSVRL1
#' @title C-SVR L1 - Support Vector Regression with C cost and L1 regularization.
#' @description Prediction for the C-SVR L1:
#'
#' f(x)=Sum_{i=1}^{N}(lambda*-lambda)K(x_{i},x)
#' @param CSVRL1 List of Results of the CSVRL1
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param Xprev Numeric matrix with the explanatory variables (predicted). Dimension equal MxP
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return Eigen::VectorXd with the predicted values for Xpred
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @name Pseudo R2 - Predicted CSVRL1
#' @title C-SVR L1 - Support Vector Regression with C cost and L1 regularization.
#' @description Prediction for the C-SVR L1:
#'
#' f(x)=Sum_{i=1}^{N}(lambda*-lambda)K(x_{i},x)
#' @param CSVRL1 List of Results of the CSVRL1
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return Eigen::VectorXd with the Pseudo R2 for each variable.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @param y Vector with dependent variables. Dimension equal Nx1.
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param epsilon Insentitive band. Should be epsilon>0.
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
NULL

CSVRL1 <- function(y, X, C, epsilon, kernel, parms) {
    .Call('mlRFinance_CSVRL1', PACKAGE = 'mlRFinance', y, X, C, epsilon, kernel, parms)
}

PredictedCSVRL1 <- function(CSVRL1, y, X, Xprev) {
    .Call('mlRFinance_PredictedCSVRL1', PACKAGE = 'mlRFinance', CSVRL1, y, X, Xprev)
}

R2PredictedCSVRL1 <- function(CSVRL1, y, X) {
    .Call('mlRFinance_R2PredictedCSVRL1', PACKAGE = 'mlRFinance', CSVRL1, y, X)
}

minimumCSVRL1 <- function(y, X, epsilon, kernel, parms) {
    .Call('mlRFinance_minimumCSVRL1', PACKAGE = 'mlRFinance', y, X, epsilon, kernel, parms)
}

#' @name CSVWQR
#' @title C-SVWQR - Support Vector Weighted Quantile Regression with C cost and L1 regularization.
#' @description Optimize the Lagrange multiplier for the C-SVWQR:
#'
#' Xu, Q., Zhang, J., Jiang, C., Huang, X., & He, Y. (2015).
#' Weighted quantile regression via support vector machine.
#' Expert Systems with Applications, 42(13), 5441-5451.
#'
#'
#' Min (1/2)u^{t}Qu+g^{t}u
#' s.t.
#' 0<=u<= tau*C*qi
#' 0<=u^{*}<= (1-tau)*C*qi
#'
#' where u=(lambda*,lambda), g=(e-y,e+y)
#' and Q=|K -K|.
#'       |-K K|
#' C is the Cost parameter and e (epsilon) is the insentitive band
#'
#' @param y Vector with dependent variables. Dimension equal Nx1.
#' @param rank Vector with the rank of the dependent variables. Dimension equal Nx1.
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param C Cost parameter. Should be C>0.
#' @param tau Quantile of interest. Should be 0<tau<1.
#' @gamma gamma Weight smooth based on Cao and Gu (2002),
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return List Support Vectors, Kernel used and parameters.
#' If the results for the Support Vectors are NaN it means that
#' there is no Support Vector and the Quadratic Programming Problem
#' is unfeasible.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @name Predicted CSVWQR
#' @title C-SVWQR - Support Vector Weighted Quantile Regression with C cost and L1 regularization.
#' @description Prediction for the C-SVWQR:
#'
#' f(x)=Sum_{i=1}^{N}(lambda*-lambda)K(x_{i},x)
#' @param CSVWQR List of Results of the CSVWQR
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param Xprev Numeric matrix with the explanatory variables (predicted). Dimension equal MxP
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return Eigen::VectorXd with the predicted values for Xpred
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

#' @name Pseudo R2 - Predicted CSVWQR
#' @title C-SVWQR - Support Vector Weighted Quantile Regression with C cost and L1 regularization.
#' @description Prediction for the C-SVWQR:
#'
#' f(x)=Sum_{i=1}^{N}(lambda*-lambda)K(x_{i},x)
#' @param CSVWQR List of Results of the CSVWQR
#' @param X Numeric matrix with the explanatory variables. Dimension equal NxP
#' @param kernel Name of the kernel that will be used.
#' @param parms Parameters associated with chosen kenel.
#' @return Eigen::VectorXd with the Pseudo R2 for each variable.
#' @examples
#'
#' A<-matrix(c(1,2,5,6,
#' 2,4,1,2),nrow=4,ncol=2)
#' d<-c(-1,-1,+1,-1)
#' svm1<- CSVML1(d, A, 1, 0.1, "Gaussian", c(0.5))
#'
#' @seealso See \code{\link{.CallOctave}}, \code{\link{o_source}}, \code{\link{o_help}}
NULL

cpp_order <- function(x, desc = FALSE) {
    .Call('mlRFinance_cpp_order', PACKAGE = 'mlRFinance', x, desc)
}

CSVWQR <- function(y, X, C, tau, gamma, kernel, parms) {
    .Call('mlRFinance_CSVWQR', PACKAGE = 'mlRFinance', y, X, C, tau, gamma, kernel, parms)
}

PredictedCSVWQR <- function(CSVWQR, X, Xprev) {
    .Call('mlRFinance_PredictedCSVWQR', PACKAGE = 'mlRFinance', CSVWQR, X, Xprev)
}

R2PredictedCSVWQR <- function(CSVWQR, X) {
    .Call('mlRFinance_R2PredictedCSVWQR', PACKAGE = 'mlRFinance', CSVWQR, X)
}

nearPDefiniteOld <- function(mat, maxit = 1e+6L, eigtol = 1e-06, conv_tol = 1e-07, posd_tol = 1e-08, keepDiagonal = FALSE) {
    .Call('mlRFinance_nearPDefiniteOld', PACKAGE = 'mlRFinance', mat, maxit, eigtol, conv_tol, posd_tol, keepDiagonal)
}

nearPDefinite <- function(X, maxit = 1e+6L, eigtol = 1e-06, conv_tol = 1e-07, posd_tol = 1e-08, keepDiagonal = FALSE) {
    .Call('mlRFinance_nearPDefinite', PACKAGE = 'mlRFinance', X, maxit, eigtol, conv_tol, posd_tol, keepDiagonal)
}

